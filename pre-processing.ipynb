{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IFT6390 Project - Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s140 = pd.read_csv('data/sentiment140.csv')\n",
    "cc = pd.read_csv('data/climatechange.csv')\n",
    "mr = pd.read_csv('data/moviereview.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s140.to_pickle('data/s140.pkl')\n",
    "cc.to_pickle('data/cc.pkl')\n",
    "mr.to_pickle('data/mr.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s140 = pd.read_pickle('data/s140.pkl')\n",
    "cc = pd.read_pickle('data/cc.pkl')\n",
    "mr = pd.read_pickle('data/mr.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/rd/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/rd/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/rd/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Natural Language Toolkit\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.tokenize import word_tokenize #creates arrays of words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#identifies words which are not adding semantic value to the sentence\n",
    "stopw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from re import sub\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "class clean:\n",
    "    def url(df:pd.DataFrame) -> pd.DataFrame:\n",
    "        # SRC -> https://stackoverflow.com/questions/51994254/removing-url-from-a-column-in-pandas-dataframe\n",
    "        return df.str.replace('http\\S+|www.\\S+', '_link_', case=False)\n",
    "    \n",
    "    def url(s:str) -> str:\n",
    "        return sub('http\\S+|www.\\S+', '_link_', s, flags=re.IGNORECASE)\n",
    "    \n",
    "    def rm_repeat(w:str) -> str:\n",
    "        \"\"\"removes letters repeated 3+ times\"\"\"\n",
    "        return sub(r'(.)\\1{2,}', r'\\1', w)\n",
    "    \n",
    "    #create an array of the words contained in each comment _\n",
    "    #while removing strings representing numbers and stopwords\n",
    "    \n",
    "    def merge(v:np.ndarray) -> str:\n",
    "        return \"\".join(w+\" \" for w in v) #converts vector into string\n",
    "    \n",
    "    def convert(s:str) -> str:\n",
    "        \"\"\"Returns a vector representation of the sentence\"\"\"\n",
    "        s=clean.url(s)\n",
    "        s=clean.rm_repeat(s)\n",
    "        #v=[w for w in word_tokenize(s) if (w not in stopw and len(w) > 1)] # create words\n",
    "        v=word_tokenize(s)\n",
    "        return \"\".join(clean.to_ascii(w)+\" \" for w in v) #converts vector into string\n",
    "    \n",
    "    def to_ascii(w:str) -> str:\n",
    "        \"\"\"Keeps ascii-only characters and appends tokens representing \n",
    "        strings of digits and non-ascii characters\"\"\"\n",
    "        onlyascii= \"\".join(i for i in w.lower() if (ord(i) < 48 or (ord(i)> 57 and ord(i)<128)))        \n",
    "        return onlyascii + clean.notascii(w) + clean.onlynumber(w)\n",
    "    \n",
    "    def onlynumber(s:str) -> str:\n",
    "        \"\"\"Returns a '_number_' token to represent any string of digits\"\"\"\n",
    "        n=\"\".join(i for i in s if (ord(i) >= 48 and ord(i)<= 57 ))\n",
    "        if (n !=\"\"):\n",
    "            return \" _number_\"\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "    def notascii(s:str) -> str:\n",
    "        \"\"\"Map strings of non-ascii characters to '_notascii_' token\"\"\"\n",
    "        symbol= \"\".join(i for i in s if ord(i) >= 128)\n",
    "        if (symbol !=\"\"):\n",
    "            return \" _notascii_\"\n",
    "        else:\n",
    "            return \"\"\n",
    "    \n",
    "    \n",
    "    #SRC -> https://www.geeksforgeeks.org/implement-isnumber-function-in-python/\n",
    "    def isNumber(s): \n",
    "        \"\"\"Considers strings of digits headed with sign characters\"\"\"\n",
    "\n",
    "        # handle for signed values\n",
    "        negative = False\n",
    "        if(s[0] =='-' or s[0] =='+'): \n",
    "            sign = True\n",
    "\n",
    "        if sign == True: \n",
    "            return clean.isNumber(s[1:]) #handles repeated signs recursively\n",
    "        else:\n",
    "            return s.isdigit()    \n",
    "\n",
    "    def normalize_text(s:str) -> str:\n",
    "        \"\"\"removes stop words, words of size 1, symbols and numbers\"\"\"\n",
    "        return [w for w in word_tokenize(clean.convert(s)) if (w not in stopw and len(w) > 1)]\n",
    "\n",
    "    def lemmatize(s:str) -> str:\n",
    "        wnl = WordNetLemmatizer()\n",
    "        return [wnl.lemmatize(w) for w in clean.normalize_text(s)]\n",
    "\n",
    "    def stem(s:str) -> str:\n",
    "        ps  = PorterStemmer()\n",
    "        return [ps.stem(w) for w in clean.normalize_text(s)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s140['lemma'] = s140['text'].apply(clean.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s140['length']=s140['lemma'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s140['trimmed']=s140['lemma'].apply(clean.merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc['lemma'] = cc['text'].apply(clean.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc['length']=cc['lemma'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc['trimmed']=cc['lemma'].apply(clean.merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc['old_target']=cc.target\n",
    "cc=cc.replace({'target': {'Yes': 'positive', 'Y': 'positive', 'No': 'negative', 'N': 'negative'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr['lemma'] = mr['text'].apply(clean.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr['length']=mr['lemma'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr['trimmed']=mr['lemma'].apply(clean.merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce cleaned dataframe for future usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s140.to_pickle('data/s140_clean_28nov.pkl')\n",
    "cc.to_pickle('data/cc_clean_28nov.pkl')\n",
    "mr.to_pickle('data/mr_clean_28nov.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s140=pd.read_pickle('data/s140_clean_28nov.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1600498\n",
      "mean           8\n",
      "std            4\n",
      "min            0\n",
      "25%            5\n",
      "50%            8\n",
      "75%           11\n",
      "max          118\n",
      "Name: length, dtype: int64\n",
      "================================================================================\n",
      "                                                text    target  \\\n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  negative   \n",
      "1  Got a headache :/ MC stop making music, you ca...  negative   \n",
      "2  lol still worked like crazy lol  . lol Your la...  negative   \n",
      "3  why won't netflix send me S. Darko? I know it'...  negative   \n",
      "4  [ToZ] Clan Website offline  http://www.theoutl...  negative   \n",
      "\n",
      "                                               lemma  length  \n",
      "0  [switchfoot, _link_, awww, 's, bummer, shoulda...      11  \n",
      "1  [got, headache, mc, stop, making, music, ca, n...      11  \n",
      "2  [lol, still, worked, like, crazy, lol, lol, la...      18  \n",
      "3  [wo, n't, netflix, send, s., darko, know, 's, ...      16  \n",
      "4              [toz, clan, website, offline, _link_]       5  \n"
     ]
    }
   ],
   "source": [
    "print(s140['length'].describe().astype('int64') )\n",
    "print('='*80)\n",
    "print(s140.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
